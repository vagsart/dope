topic_camera: "/dope/webcam/image_raw"
topic_camera_info: "/dope/webcam/camera_info"
topic_publishing: "dope"
input_is_rectified: True   # Whether the input image is rectified (strongly suggested!)
downscale_height: 480   # if the input image is larger than this, scale it down to this pixel height

# Comment any of these lines to prevent detection / pose estimation of that object
weights: {
    "obj_1": "/data/training_log/net_epoch_49.pth",
    "obj_2": "/data/training_log/net_epoch_49.pth",
    "obj_3": "/data/training_log/net_epoch_49.pth",
    "obj_4": "/data/training_log/net_epoch_49.pth",
    "obj_5": "/data/training_log/net_epoch_49.pth"    
}

# Type of neural network architecture
architectures: {
    "obj_1": "dope",
    "obj_2": "dope",
    "obj_3": "dope",
    "obj_4": "dope",
    "obj_5": "dope"
}


# Cuboid dimension in cm x,y,z
dimensions: {
    "obj_1": [15.899969482421875, 24.85395050048828, 7.419580078125],
    "obj_2": [6.614794921875, 20.2759033203125, 6.6885009765625],
    "obj_3": [9.778550720214844, 42.2700012207031255, 7.41875],
    "obj_4": [6.580763, 11.633094, 7.075945],
    "obj_5": [18.394457, 24.826819999999998, 2.7396]
}

class_ids: {
    "obj_1": 1,
    "obj_2": 2,
    "obj_3": 3,
    "obj_4": 4,
    "obj_5": 5
}

draw_colors: {
    "obj_1": [255, 0, 0],
    "obj_2": [0, 255, 0],
    "obj_3": [0, 0, 255],
    "obj_4": [255, 255, 0],
    "obj_5": [255, 0, 255],
}

# optional: provide a transform that is applied to the pose returned by DOPE
model_transforms: {
#    "cracker": [[ 0,  0,  1,  0],
#                [ 0, -1,  0,  0],
#                [ 1,  0,  0,  0],
#                [ 0,  0,  0,  1]]
}

# optional: if you provide a mesh of the object here, a mesh marker will be
# published for visualization in RViz
# You can use the nvdu_ycb tool to download the meshes: https://github.com/NVIDIA/Dataset_Utilities#nvdu_ycb
meshes: {
#    "cracker": "file://path/to/Dataset_Utilities/nvdu/data/ycb/aligned_cm/003_cracker_box/google_16k/textured.obj",
#    "gelatin": "file://path/to/Dataset_Utilities/nvdu/data/ycb/aligned_cm/009_gelatin_box/google_16k/textured.obj",
#    "meat":    "file://path/to/Dataset_Utilities/nvdu/data/ycb/aligned_cm/010_potted_meat_can/google_16k/textured.obj",
#    "mustard": "file://path/to/Dataset_Utilities/nvdu/data/ycb/aligned_cm/006_mustard_bottle/google_16k/textured.obj",
#    "soup":    "file://path/to/Dataset_Utilities/nvdu/data/ycb/aligned_cm/005_tomato_soup_can/google_16k/textured.obj",
#    "sugar":   "file://path/to/Dataset_Utilities/nvdu/data/ycb/aligned_cm/004_sugar_box/google_16k/textured.obj",
#    "bleach":  "file://path/to/Dataset_Utilities/nvdu/data/ycb/aligned_cm/021_bleach_cleanser/google_16k/textured.obj",
}

# optional: If the specified meshes are not in meters, provide a scale here (e.g. if the mesh is in centimeters, scale should be 0.01). default scale: 1.0.
mesh_scales: {
    "obj_1": 0.001,
    "obj_2": 0.001,
    "obj_3": 0.001,
    "obj_4": 0.001,
    "obj_5": 0.001
}

# Config params for DOPE
thresh_angle: 0.5
thresh_map: 0.0001
sigma: 3
thresh_points: 0.1
